name: Website Monitor

# Example configuration (edit these values to change the default monitoring settings)
env:
  DEFAULT_WEBSITE_URL: 'https://owaspblt.org'
  DEFAULT_KEYWORD: 'OWASP'

on:
  push:
  schedule:
    - cron: '*/5 * * * *'  # Run every 5 minutes
  workflow_dispatch:  # Allow manual triggering
    inputs:
      website_url:
        description: 'Website URL to monitor (default: https://owasp.org)'
        required: false
        default: 'https://owasp.org'
      keyword:
        description: 'Keyword to check for in website content (default: OWASP)'
        required: false
        default: 'OWASP'

# Set the permissions for the workflow
permissions:
  contents: write
  pull-requests: write
  pages: write
  id-token: write

jobs:
  monitor:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          fetch-depth: 0  # Fetch all history for all branches and tags

      - name: Monitor all websites
        id: monitor
        run: |
          # If manual trigger with custom URL, use that
          if [ -n "${{ github.event.inputs.website_url }}" ]; then
            echo "Manual trigger detected - monitoring single URL"
            MONITORS='[{"id":"manual","name":"Manual","url":"${{ github.event.inputs.website_url }}","keyword":"${{ github.event.inputs.keyword }}"}]'
          else
            # Read all monitors from monitors.json
            MONITORS=$(cat monitors.json)
          fi

          # Use temp file for collecting failures (avoids subshell issues)
          failed_monitors_file=$(mktemp)
          > "$failed_monitors_file"

          # Loop through each monitor (using process substitution instead of pipe to avoid subshell)
          while read -r monitor; do
            id=$(echo "$monitor" | jq -r '.id')
            name=$(echo "$monitor" | jq -r '.name')
            url=$(echo "$monitor" | jq -r '.url')
            keyword=$(echo "$monitor" | jq -r '.keyword')

            echo "Monitoring: $name ($url)"

            # Monitor the website
            start_time=$(date +%s%3N)
            content=$(curl -s "$url")
            response_code=$(curl -s -o /dev/null -w "%{http_code}" "$url")
            end_time=$(date +%s%3N)
            duration_ms=$((end_time - start_time))
            duration_s=$(awk "BEGIN {printf \"%.3f\", $duration_ms/1000}")

            # Check for keyword
            if echo "$content" | grep -qi "$keyword"; then
              keyword_status="found"
            else
              keyword_status="not_found"
            fi

            # Check for Cloudflare captcha message
            cloudflare_captcha=false
            if echo "$content" | grep -qi "Verify you are human by completing the action below"; then
              cloudflare_captcha=true
            fi

            # Determine status
            if [ "$keyword_status" == "found" ] || [ "$cloudflare_captcha" == "true" ]; then
              status="success"
            else
              status="failure"
              # Append to failed monitors list
              echo "- $name ($url) - keyword '$keyword' not found" >> "$failed_monitors_file"
            fi

            echo "Result: $status (keyword: $keyword_status, duration: ${duration_s}s)"

            # Update status file for this monitor
            status_file="status-${id}.csv"
            now_iso=$(date -Iseconds)

            if [ ! -s "$status_file" ]; then
              echo "datetime,duration_ms,status,keyword_status" > "$status_file"
            fi

            echo "$now_iso,$duration_ms,$status,$keyword_status" >> "$status_file"

            # Keep only last 30 data rows (plus header) - properly handle header
            if [ "$(wc -l < "$status_file")" -gt 31 ]; then
              head -n 1 "$status_file" > "${status_file}.tmp"
              tail -n +2 "$status_file" | tail -n 30 >> "${status_file}.tmp"
              mv "${status_file}.tmp" "$status_file"
            fi
          done < <(echo "$MONITORS" | jq -c '.[]')

          # Set output variables based on collected failures
          if [ -s "$failed_monitors_file" ]; then
            echo "has_failures=true" >> $GITHUB_OUTPUT
            failed_list=$(tr '\n' ' ' < "$failed_monitors_file")
            echo "failed_monitors=$failed_list" >> $GITHUB_OUTPUT
          else
            echo "has_failures=false" >> $GITHUB_OUTPUT
            echo "failed_monitors=" >> $GITHUB_OUTPUT
          fi

          rm -f "$failed_monitors_file"

          # Also update the legacy status.csv for backward compatibility (uses first monitor or manual input)
          if [ -n "${{ github.event.inputs.website_url }}" ]; then
            # Manual trigger - use provided values
            start_time=$(date +%s%3N)
            content=$(curl -s "${{ github.event.inputs.website_url }}")
            end_time=$(date +%s%3N)
            duration_ms=$((end_time - start_time))

            if echo "$content" | grep -qi "${{ github.event.inputs.keyword }}"; then
              keyword_status="found"
              status="success"
            else
              keyword_status="not_found"
              status="failure"
            fi

            cloudflare_captcha=false
            if echo "$content" | grep -qi "Verify you are human by completing the action below"; then
              cloudflare_captcha=true
              status="success"
            fi

            now_iso=$(date -Iseconds)
            if [ ! -s status.csv ]; then
              echo "datetime,duration_ms,status,keyword_status" > status.csv
            fi
            echo "$now_iso,$duration_ms,$status,$keyword_status" >> status.csv

            # Keep only last 30 data rows (plus header) - properly handle header
            if [ "$(wc -l < status.csv)" -gt 31 ]; then
              head -n 1 status.csv > status.csv.tmp
              tail -n +2 status.csv | tail -n 30 >> status.csv.tmp
              mv status.csv.tmp status.csv
            fi
          fi

      # Note: index.html generation was removed to support the new multi-monitor homepage
      # index.html is now a static page that lists all monitors from monitors.json
      # monitor.html dynamically loads monitor details based on URL parameter

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add status*.csv
          git commit -m "Update website monitor status" || true
          git pull --rebase origin main || true
          git push origin main

      - name: Notify Slack on failure
        if: steps.monitor.outputs.has_failures == 'true'
        uses: slackapi/slack-github-action@v1.24.0
        with:
          payload: |
            {
              "text": "⚠️ Website Monitor Alert\nOne or more monitors detected issues:\n${{ steps.monitor.outputs.failed_monitors }}\nMonitor Dashboard: https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

      - name: Upload GitHub Pages artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: .

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
